<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Efficient Det paper summary | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Efficient Det paper summary" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Efficient Object Detection based on NAS, Path Aggregation and weighted feature fusion" />
<meta property="og:description" content="Efficient Object Detection based on NAS, Path Aggregation and weighted feature fusion" />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/eff_det.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-15T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-07-15T00:00:00-05:00","dateModified":"2020-07-15T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html"},"description":"Efficient Object Detection based on NAS, Path Aggregation and weighted feature fusion","image":"https://cedric-perauer.github.io/DL_from_Foundations/images/eff_det.png","@type":"BlogPosting","url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html","headline":"Efficient Det paper summary","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/DL_from_Foundations/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/DL_from_Foundations/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Efficient Det paper summary | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Efficient Det paper summary" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Efficient Object Detection based on NAS, Path Aggregation and weighted feature fusion" />
<meta property="og:description" content="Efficient Object Detection based on NAS, Path Aggregation and weighted feature fusion" />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/eff_det.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-15T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-07-15T00:00:00-05:00","dateModified":"2020-07-15T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html"},"description":"Efficient Object Detection based on NAS, Path Aggregation and weighted feature fusion","image":"https://cedric-perauer.github.io/DL_from_Foundations/images/eff_det.png","@type":"BlogPosting","url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html","headline":"Efficient Det paper summary","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/DL_from_Foundations/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/DL_from_Foundations/about/">About Me</a><a class="page-link" href="/DL_from_Foundations/search/">Search</a><a class="page-link" href="/DL_from_Foundations/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Efficient Det paper summary</h1><p class="page-description">Efficient Object Detection based on NAS, Path Aggregation and weighted feature fusion</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-15T00:00:00-05:00" itemprop="datePublished">
        Jul 15, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/DL_from_Foundations/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/Cedric-Perauer/DL_from_Foundations/tree/master/_notebooks/2020-07-15-EfficientDet.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/DL_from_Foundations/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/Cedric-Perauer/DL_from_Foundations/master?filepath=_notebooks%2F2020-07-15-EfficientDet.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/DL_from_Foundations/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/Cedric-Perauer/DL_from_Foundations/blob/master/_notebooks/2020-07-15-EfficientDet.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/DL_from_Foundations/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#What-did-the-authors-want-to-achieve-?">What did the authors want to achieve ? </a></li>
<li class="toc-entry toc-h2"><a href="#Methods">Methods </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Challenges">Challenges </a></li>
<li class="toc-entry toc-h3"><a href="#BiFPN">BiFPN </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Problem">Problem </a></li>
<li class="toc-entry toc-h4"><a href="#Cross-Scale-Connections">Cross-Scale Connections </a></li>
<li class="toc-entry toc-h4"><a href="#Weighted-Feature-Fusion">Weighted Feature Fusion </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Architecture">Architecture </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Backbone">Backbone </a></li>
<li class="toc-entry toc-h4"><a href="#BiFPN-Net">BiFPN Net </a></li>
<li class="toc-entry toc-h4"><a href="#Box/class-prediction-network">Box/class prediction network </a></li>
<li class="toc-entry toc-h4"><a href="#Image-Resolution">Image Resolution </a></li>
<li class="toc-entry toc-h4"><a href="#Some-Implementation-Details">Some Implementation Details </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Results">Results </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-15-EfficientDet.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-did-the-authors-want-to-achieve-?">
<a class="anchor" href="#What-did-the-authors-want-to-achieve-?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What did the authors want to achieve ?<a class="anchor-link" href="#What-did-the-authors-want-to-achieve-?"> </a>
</h2>
<p>Recently, the SOTA in high accuracy in the fields of object detection and semantic segmentation were mostly achieved by scaling up architectures (e.g. AmoebaNet and NAS-FPN). 
These models are not easily deployable, especially in runtime/compute constrained applications such as autonomous driving. While existing worked has achieved faster rutime through one-stage/anchor-free detectors or model compression, they usually sacrifice accuracy for runtime. The goal is therefore to create an architecture that combines the best of both worlds, and achieve both high accuracy and better efficiency. The authors consider a wide range of compute that someone might have at hand during inference (3B to 300B FLOPS).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Methods">
<a class="anchor" href="#Methods" aria-hidden="true"><span class="octicon octicon-link"></span></a>Methods<a class="anchor-link" href="#Methods"> </a>
</h2>
<h3 id="Challenges">
<a class="anchor" href="#Challenges" aria-hidden="true"><span class="octicon octicon-link"></span></a>Challenges<a class="anchor-link" href="#Challenges"> </a>
</h3>
<p>The authors define 2 main challenges :</p>
<p>1) efficient multi-scale feature fusion</p>
<p>The authors do consider recent developments like PANet and NAS-FPN (both improvments of the original FPN approach). Most of these works only sum up the features without weighting them, even though the resolutions are different. That's why the authors of the paper propose a weighted bi-directional feature pyramid network (BiFPN), it introduces weights that can learn the importance of a different input features. It does this while also applying top-down and bottom-up bath augmentation as proposed in the PANet paper.</p>
<p>2) model scaling</p>
<p>In the past, the main method to improve performance, was using larger and therefore more powerful backbones. In this paper the authors use NAS to jointly scale resolution of the input, depth and width of the net as well as sclaing the feature network and box/class prediction network. It thus follows the ideas of EfficientNet, which also turns out to be their backbone choice. The architectures that are proposed is therefore a combo of EfficientNet, BiPFN and compound scaling. These models are called EfficientDet, in honor of their Backbone.</p>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/FPNs.png" alt="image"> 
$Figure$ $1$</p>
<h3 id="BiFPN">
<a class="anchor" href="#BiFPN" aria-hidden="true"><span class="octicon octicon-link"></span></a>BiFPN<a class="anchor-link" href="#BiFPN"> </a>
</h3>
<h4 id="Problem">
<a class="anchor" href="#Problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problem<a class="anchor-link" href="#Problem"> </a>
</h4>
<p>BiFPN aims to aggregate features at different resolutions, as FPN-ish methods downscale the feature level with a resolution of $1/2^{i}$ ($i$ being the layer number) , up-/downsampling is used in order to match features of different resolution.</p>
<h4 id="Cross-Scale-Connections">
<a class="anchor" href="#Cross-Scale-Connections" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cross-Scale Connections<a class="anchor-link" href="#Cross-Scale-Connections"> </a>
</h4>
<p>In their research the authors compare PANet (introduces bottom-up aggregation) with FPN and NAS-FPN and find that PANet achieves the best accuracy at the cost of some compute overhead. The authors improve upon these cross-scale connections by removing and thereby simplifying nodes with only one input edge, as these have less contribution to the feature net. Secondly they connect an extra edge from input to output node if they are at the same level (fusion with low compute cost), also see $Figure$ $1$. Furthermore, each bidirectional layer (top-down and bottom-up bath) is repeated multiple times to enable higher level fusion. For concrete implementation details (# of layers), refer to section 4.2 in the paper.</p>
<h4 id="Weighted-Feature-Fusion">
<a class="anchor" href="#Weighted-Feature-Fusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Weighted Feature Fusion<a class="anchor-link" href="#Weighted-Feature-Fusion"> </a>
</h4>
<p>As explained earlier, the different resolutions that the feature maps have should be considered and therefore weithed during aggregation. In this work the authors use Pyramid Attention Network, which uses global self-attention upsampling to recover the location of the pixels. In order to weigh each input seperately, an additional learnable weight is added for each input. The authors consider three different fusion approaches :</p>
<p>1) Unbounded Fusion : $0 = \sum\limits_{i} w_{i} * I_{i}$
=&gt; could lead to instability, so weight norm is applied here</p>
<p>2) Softmax-based function : $O = \sum\limits_{i} \dfrac{e^{w_{i}}}{\sum\limits_{j} e{w_{j}}} * I_{i}$<br>
=&gt; here the idea is to normalize the probablities between 0 and 1, weighting the importance of each input that way. However the softmax introduces extra slowdown on the GPU hardware, so 3) is proposed :</p>
<p>3) Fast normalized fusion : $O = \sum\limits_{i} \dfrac}{\epsilon + \sum\limits_{j}  {w_{j}}} * I_{i}$</p>
<p>This function has the same learning charaterstics as 2), but it runs about 30% faster on GPU  Depthwise sep. convs are used for better runtime.</p>
<h3 id="Architecture">
<a class="anchor" href="#Architecture" aria-hidden="true"><span class="octicon octicon-link"></span></a>Architecture<a class="anchor-link" href="#Architecture"> </a>
</h3>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/eff_arch.png" alt="image">
$Figure$ $2$</p>
<p>To create the final architecture a new compound scaling method is introduced which scales Backbone,BiFPN, class/box net and resolution jointly. A heuristics used as object detectors have even more possible configs as classification nets.</p>
<h4 id="Backbone">
<a class="anchor" href="#Backbone" aria-hidden="true"><span class="octicon octicon-link"></span></a>Backbone<a class="anchor-link" href="#Backbone"> </a>
</h4>
<p>In order to use ImageNet pretraining, the checkpoints of EfficientNet-B0 to B6 are used.</p>
<h4 id="BiFPN-Net">
<a class="anchor" href="#BiFPN-Net" aria-hidden="true"><span class="octicon octicon-link"></span></a>BiFPN Net<a class="anchor-link" href="#BiFPN-Net"> </a>
</h4>
<p>The BiFPN depth is linearly increased. The width is scaled exponentially, a grid search is done and 1.35 is used as a base :</p>
<p>$W_{BiFPN} = 64 * (1.35^{\theta})$<br>
$D_{BiFPN} = 3 + \theta$</p>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/efficient_nas.png" alt="images"></p>
<h4 id="Box/class-prediction-network">
<a class="anchor" href="#Box/class-prediction-network" aria-hidden="true"><span class="octicon octicon-link"></span></a>Box/class prediction network<a class="anchor-link" href="#Box/class-prediction-network"> </a>
</h4>
<p>Width is fixed to be same as BiFPN, but depth is increased differently : 
$D_{box} = D_{class} = 3 + [\theta/3]$</p>
<h4 id="Image-Resolution">
<a class="anchor" href="#Image-Resolution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image Resolution<a class="anchor-link" href="#Image-Resolution"> </a>
</h4>
<p>Image res. is increased using equation : $R_{input} = 512 + \theta * 128$<br>
128 is used as the features are used in level 3-7 and $2^{7} = 128$</p>
<p>Heuristics based scaling might not be optimal and could be improved.</p>
<p>The scaling results can be seen below : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/eff_nas.png" alt="images"></p>
<p>The advantage of compound scaling is shown in $Figure$ $2$.</p>
<h4 id="Some-Implementation-Details">
<a class="anchor" href="#Some-Implementation-Details" aria-hidden="true"><span class="octicon octicon-link"></span></a>Some Implementation Details<a class="anchor-link" href="#Some-Implementation-Details"> </a>
</h4>
<ul>
<li>SGD with momentum 0.9 and weight decay 4e-5   </li>
<li>Synch BN w/BN decay of 0.99 end epsilon 1e-3   </li>
<li>swish activation with weight decay of 0.9998 </li>
<li>focal-loss with α = 0.25 and γ = 1.5, and aspect ratio {1/2, 1, 2}</li>
<li>RetinaNnet preprocessing with training-time flip-
ping and scaling</li>
<li>soft NMS is used for D7, standard NMS for the others</li>
</ul>
<h3 id="Results">
<a class="anchor" href="#Results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results<a class="anchor-link" href="#Results"> </a>
</h3>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/eff_det.png" alt=""></p>
<p>As the graph above shows, EfficientDet-D0 performs about on par with YOLOv3. It does use 28x fewer flops, which does not directly show in the runtime (also due to the optimized TensorRT implementation that YOLOv3 uses). Overall it is about 4-9x smaller and 13-42x less FLOP hungry than other detectors. In total they are about 4.1x faster on GPU and even 10x faster on CPU. This is probably due to the fact that the CPU can not hide the extra compute requierements in FLOPS as efficiently as the latency hiding GPU architecture.</p>
<p>The authors compete on a Segmentation task and outperform DeepLabV3+ by 1.7% on COCO Segmentation with 9.8x fewer FLOPS.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Cedric-Perauer/DL_from_Foundations"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/DL_from_Foundations/jupyter/2020/07/15/EfficientDet.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/DL_from_Foundations/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/DL_from_Foundations/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
