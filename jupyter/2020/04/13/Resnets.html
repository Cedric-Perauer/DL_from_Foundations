<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Summary of the ResNet paper | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Summary of the ResNet paper" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Allowing the training of deeper Networks, than seen before." />
<meta property="og:description" content="Allowing the training of deeper Networks, than seen before." />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_net.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-13T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-04-13T00:00:00-05:00","dateModified":"2020-04-13T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html"},"description":"Allowing the training of deeper Networks, than seen before.","image":"https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_net.png","@type":"BlogPosting","url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html","headline":"Summary of the ResNet paper","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/DL_from_Foundations/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/DL_from_Foundations/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Summary of the ResNet paper | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Summary of the ResNet paper" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Allowing the training of deeper Networks, than seen before." />
<meta property="og:description" content="Allowing the training of deeper Networks, than seen before." />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_net.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-13T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-04-13T00:00:00-05:00","dateModified":"2020-04-13T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html"},"description":"Allowing the training of deeper Networks, than seen before.","image":"https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_net.png","@type":"BlogPosting","url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/13/Resnets.html","headline":"Summary of the ResNet paper","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/DL_from_Foundations/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/DL_from_Foundations/about/">About Me</a><a class="page-link" href="/DL_from_Foundations/search/">Search</a><a class="page-link" href="/DL_from_Foundations/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Summary of the ResNet paper</h1><p class="page-description">Allowing the training of deeper Networks, than seen before.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-13T00:00:00-05:00" itemprop="datePublished">
        Apr 13, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/DL_from_Foundations/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Summary-of-the-ResNet-paper">Summary of the ResNet paper </a>
<ul>
<li class="toc-entry toc-h3"><a href="#What-did-the-authors-want-to-achieve-?">What did the authors want to achieve ? </a></li>
<li class="toc-entry toc-h3"><a href="#Key-elements">Key elements </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Residual-Learning">Residual Learning </a></li>
<li class="toc-entry toc-h4"><a href="#Shortcuts">Shortcuts </a></li>
<li class="toc-entry toc-h4"><a href="#Deeper-Bottleneck-Architectures">Deeper Bottleneck Architectures </a></li>
<li class="toc-entry toc-h4"><a href="#Implementation-Details">Implementation Details </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Implementation-of-a-ResBlock">Implementation of a ResBlock </a></li>
<li class="toc-entry toc-h3"><a href="#Results-and-Conclusion">Results and Conclusion </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-13-Resnets.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary-of-the-ResNet-paper">
<a class="anchor" href="#Summary-of-the-ResNet-paper" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary of the <a href="https://arxiv.org/pdf/1512.03385.pdf">ResNet paper</a><a class="anchor-link" href="#Summary-of-the-ResNet-paper"> </a>
</h2>
<p>The architecture that won the 1st place on the
ILSVRC 2015 classification task.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-did-the-authors-want-to-achieve-?">
<a class="anchor" href="#What-did-the-authors-want-to-achieve-?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What did the authors want to achieve ?<a class="anchor-link" href="#What-did-the-authors-want-to-achieve-?"> </a>
</h3>
<ul>
<li>Allow training of deep Networks </li>
<li>Improve Computer Vision Performance, by enabling the use of deeper architectures as depth is of crucial importance (as can be seen with to other ImageNet winners) 
=&gt; This applies to different vision tasks </li>
<li>Normalization and Initialization have largely adressed vanishing/exploding gradients in deep networks, however accuracy gets saturated and then degrates quickly with more depth :<br>
deep residual learning should help adress this issue and build on existing ideas such as shortcut connections </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Key-elements">
<a class="anchor" href="#Key-elements" aria-hidden="true"><span class="octicon octicon-link"></span></a>Key elements<a class="anchor-link" href="#Key-elements"> </a>
</h3>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/resnet_net.png" alt="images"></p>
<h4 id="Residual-Learning">
<a class="anchor" href="#Residual-Learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Residual Learning<a class="anchor-link" href="#Residual-Learning"> </a>
</h4>
<ul>
<li>$H(X)$ is considered to be the mapping of a few stacked layers. The idea of Residual Blocks, is that this mapping function $H(x) = F(x) + x$ can more easily be learned when we let it approximate this Residual funciton. This is based on the degradation problem, which suggests that the solvers
might have difficulties in approximating identity mappings
by multiple nonlinear layers. The identity mapping should then allow deeper models to have an error no greater than that of a shallow counterpart. In reality, the identity mapping probably is not optimal, but it can still allow us to pre-condition the problem. This is shown by the small responese of the learned residual functions, which suggest that these mappings provide reasonable preconditioning. If the residual funciton has only a single layer, it resembles a linear function $y = W*x +x$, which is why an advantage can only be observed with more than one layer. </li>
</ul>
<p>The comparison between a plain 34-layer and 34-layer residual network looks like this : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/Resnet_idea.png" alt=""></p>
<h4 id="Shortcuts">
<a class="anchor" href="#Shortcuts" aria-hidden="true"><span class="octicon octicon-link"></span></a>Shortcuts<a class="anchor-link" href="#Shortcuts"> </a>
</h4>
<p>3 different Shortcuts are used :</p>
<p>A) zero-padding shortcuts are used<br>
for increasing dimensions, and all shortcuts are parameterfree<br>
B) ) projection shortcuts are used for increasing dimensions, and other
shortcuts are identity<br>
C)  all shortcuts are projections</p>
<p>All 3 above are better than the plain counterpart, however C is slightly better than B, which is also slighlty better than A (see Table 4, under Classification). But the small differences are not essential for the degradation problem, and C adds parameters which has a negative impact on time/memory complexity.</p>
<h4 id="Deeper-Bottleneck-Architectures">
<a class="anchor" href="#Deeper-Bottleneck-Architectures" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deeper Bottleneck Architectures<a class="anchor-link" href="#Deeper-Bottleneck-Architectures"> </a>
</h4>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/bottleneck.png" alt="">
Because of training time, the block is redesigned as a bottleneck with smaller I/O dimensions. The three layers
are 1×1, 3×3, and 1×1 convolutions, where the 1×1 layers
are responsible for reducing and then increasing (restoring)
dimensions, leaving the 3×3 layer a bottleneck with smaller
input/output dimensions. Identity shortcut connections are key, as with projection the model size and time complexity would double.</p>
<h4 id="Implementation-Details">
<a class="anchor" href="#Implementation-Details" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation Details<a class="anchor-link" href="#Implementation-Details"> </a>
</h4>
<ul>
<li>224x224 random crop is randomly sampled from an image, horizontal flips are used</li>
<li>SGD is used with lr starting at 0.1 and being divided by 10 as the error plateaus</li>
<li>training for up to 60x1e5 iterations</li>
<li>weight decay : 0.0001 and momentum of 0.9</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation-of-a-ResBlock">
<a class="anchor" href="#Implementation-of-a-ResBlock" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation of a ResBlock<a class="anchor-link" href="#Implementation-of-a-ResBlock"> </a>
</h3>
<p>A Residual Block can be implemented as follows in PyTorch :</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Creates a convolutional layer, with optional batch normalization.</span>
<span class="sd">    """</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span><span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_layer</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Resblock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> 
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">conv_dim</span><span class="p">):</span> 
        <span class="nb">super</span><span class="p">(</span><span class="n">Resblock</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">conv_dim</span><span class="p">,</span> <span class="n">conv_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">conv_dim</span><span class="p">,</span> <span class="n">conv_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span> 
        <span class="n">out1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span>  <span class="n">x</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">def</span> <span class="nf">resblocks_create</span><span class="p">(</span><span class="n">conv_dim</span><span class="p">,</span><span class="n">n_res_blocks</span><span class="p">):</span>
    <span class="n">res_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n_res_blocks</span><span class="p">):</span>
        <span class="n">res_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Resblock</span><span class="p">(</span><span class="n">conv_dim</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">res_layers</span><span class="p">)</span>
</pre></div>
<p>Instead of the conv function, you could obviously use the Impl</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Results-and-Conclusion">
<a class="anchor" href="#Results-and-Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results and Conclusion<a class="anchor-link" href="#Results-and-Conclusion"> </a>
</h3>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/res_layout.png" alt="images"></p>
<p>Classification :</p>
<ul>
<li>the models are trained on the 1.28 million training images of ImageNet 2012. The 50k images val set and 100k images test set is used. At first Plain Networks are compared to it's respective ResNet with identity mapping and 0 padding, which does not add extra parameters. The results show that the degradation error is adressed better which allows better performance with increased depth and allowed them to win the ImageNet Challenge in 2015. The experiments show that depth matters as it allows lower classification error :<br>
<img src="/DL_from_Foundations/images/copied_from_nb/images/imagenet_archs.png" alt="">
</li>
</ul>
<p>Object Detection :</p>
<ul>
<li>Faster R-CNN is used, but unlike VGG-16, no hidden layers are used. A full images shared feature map is computed, using layers whose stride on the image is not greater than 16 pixels. (i.e., conv1, conv2 x, conv3 x, and conv4 x, totally 91 conv
layers in ResNet-101) These layers are anologous to VGG-16's 13 conv-layers and thereby have the same total stride (16 pixels). In consequence these layers are shared by a RPN with 300 proposals. . RoI pooling is performed before conv5_1.  On this RoI-pooled
feature, all layers of conv5 x and up are adopted for each
region, playing the roles of VGG-16’s fc layers. Sibling layers (classification and bounding box regression) are used to replace the final classification layer. The BN layers are fixed, based on each layers Image Net mean and variance statistic.  With this technique, using ResNet-101 the mAP (@0.5 IOU) can be improved a lot : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/imagenet_detection.png" alt="">
</li>
</ul>
<p>Object localization :</p>
<ul>
<li>a per class regression strategy is used (Bounding Box regressor for each class is learned). The Region Proposal Network ends with two sibling 1x1 convs for binary classification. So the Classification layer has a 1000 Dimension output, and for each dimension we predict if it is this object or not (binary). The regression layer has a 1000x4 d output, with box regressors for all 1000 classes based on multiple translation-invariant anchor boxes. Usually 8 acnhors are randomply sampled from the image, this avoids the dominance of negative samples. Data Augmentation is used, by sampling random 224x224 crops. Using ResNet-101 the state of the art can be improved : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/imagenet_local.png" alt="">
</li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Cedric-Perauer/DL_from_Foundations"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/DL_from_Foundations/jupyter/2020/04/13/Resnets.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/DL_from_Foundations/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/DL_from_Foundations/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
