<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Fastai Course DL from the Foundations Mixed Precision Training | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Fastai Course DL from the Foundations Mixed Precision Training" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="FP16 advanteges and GPU understanding (Lesson 5 Part 2)" />
<meta property="og:description" content="FP16 advanteges and GPU understanding (Lesson 5 Part 2)" />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/logo.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-21T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"FP16 advanteges and GPU understanding (Lesson 5 Part 2)","@type":"BlogPosting","headline":"Fastai Course DL from the Foundations Mixed Precision Training","dateModified":"2020-04-21T00:00:00-05:00","datePublished":"2020-04-21T00:00:00-05:00","url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html"},"image":"https://cedric-perauer.github.io/DL_from_Foundations/images/logo.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/DL_from_Foundations/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/DL_from_Foundations/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Fastai Course DL from the Foundations Mixed Precision Training | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Fastai Course DL from the Foundations Mixed Precision Training" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="FP16 advanteges and GPU understanding (Lesson 5 Part 2)" />
<meta property="og:description" content="FP16 advanteges and GPU understanding (Lesson 5 Part 2)" />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/logo.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-21T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"FP16 advanteges and GPU understanding (Lesson 5 Part 2)","@type":"BlogPosting","headline":"Fastai Course DL from the Foundations Mixed Precision Training","dateModified":"2020-04-21T00:00:00-05:00","datePublished":"2020-04-21T00:00:00-05:00","url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/21/2fp16.html"},"image":"https://cedric-perauer.github.io/DL_from_Foundations/images/logo.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/DL_from_Foundations/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/DL_from_Foundations/search/">Search</a><a class="page-link" href="/DL_from_Foundations/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Fastai Course DL from the Foundations Mixed Precision Training</h1><p class="page-description">FP16 advanteges and GPU understanding (Lesson 5 Part 2)</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-21T00:00:00-05:00" itemprop="datePublished">
        Apr 21, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      16 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/DL_from_Foundations/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/Cedric-Perauer/DL_from_Foundations/tree/master/_notebooks/2020-04-21-2fp16.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/DL_from_Foundations/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/Cedric-Perauer/DL_from_Foundations/master?filepath=_notebooks%2F2020-04-21-2fp16.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/DL_from_Foundations/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/Cedric-Perauer/DL_from_Foundations/blob/master/_notebooks/2020-04-21-2fp16.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/DL_from_Foundations/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Fastai-Training-in-mixed-precision">Fastai Training in mixed precision </a>
<ul>
<li class="toc-entry toc-h2"><a href="#A-little-bit-of-theory">A little bit of theory </a>
<ul>
<li class="toc-entry toc-h3"><a href="#What's-half-precision?">What&#39;s half precision? </a></li>
<li class="toc-entry toc-h3"><a href="#Problems-with-half-precision:">Problems with half-precision: </a></li>
<li class="toc-entry toc-h3"><a href="#The-solution:-mixed-precision-training">The solution: mixed precision training </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Util-functions">Util functions </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Converting-the-model-to-FP16">Converting the model to FP16 </a></li>
<li class="toc-entry toc-h3"><a href="#Creating-the-master-copy-of-the-parameters">Creating the master copy of the parameters </a></li>
<li class="toc-entry toc-h3"><a href="#Copy-the-gradients-from-model-params-to-master-params">Copy the gradients from model params to master params </a></li>
<li class="toc-entry toc-h3"><a href="#Copy-the-master-params-to-the-model-params">Copy the master params to the model params </a></li>
<li class="toc-entry toc-h3"><a href="#But-we-need-to-handle-param-groups">But we need to handle param groups </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#The-main-Callback">The main Callback </a></li>
<li class="toc-entry toc-h2"><a href="#Dynamic-loss-scaling">Dynamic loss scaling </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-21-2fp16.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Fastai-Training-in-mixed-precision">
<a class="anchor" href="#Fastai-Training-in-mixed-precision" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fastai Training in mixed precision<a class="anchor-link" href="#Fastai-Training-in-mixed-precision"> </a>
</h1>
<p>FP16 should allow up to 8-10x speed ups in theory, practically it also depends on the number of specialized cores on the GPU as well as Software configurations of the GPU driver.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="kn">from</span> <span class="nn">exp.nb_10b</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-little-bit-of-theory">
<a class="anchor" href="#A-little-bit-of-theory" aria-hidden="true"><span class="octicon octicon-link"></span></a>A little bit of theory<a class="anchor-link" href="#A-little-bit-of-theory"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://course.fast.ai/videos/?lesson=12&amp;t=1318">Jump_to lesson 12 video</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Continuing the documentation on the fastai_v1 development here is a brief piece about mixed precision training. A very nice and clear introduction to it is <a href="http://on-demand.gputechconf.com/gtc/2018/video/S81012/">this video from NVIDIA</a>.</p>
<h3 id="What's-half-precision?">
<a class="anchor" href="#What's-half-precision?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What's half precision?<a class="anchor-link" href="#What's-half-precision?"> </a>
</h3>
<p>In neural nets, all the computations are usually done in single precision, which means all the floats in all the arrays that represent inputs, activations, weights... are 32-bit floats (FP32 in the rest of this post). An idea to reduce memory usage (and avoid those annoying cuda errors) has been to try and do the same thing in half-precision, which means using 16-bits floats (or FP16 in the rest of this post). By definition, they take half the space in RAM, and in theory could allow you to double the size of your model and double your batch size.</p>
<p>Another very nice feature is that NVIDIA developed its latest GPUs (the Volta generation) to take fully advantage of half-precision tensors. Basically, if you give half-precision tensors to those, they'll stack them so that each core can do more operations at the same time, and theoretically gives an 8x speed-up (sadly, just in theory).</p>
<p>So training at half precision is better for your memory usage, way faster if you have a Volta GPU (still a tiny bit faster if you don't since the computations are easiest). How do we do it? Super easily in pytorch, we just have to put .half() everywhere: on the inputs of our model and all the parameters. Problem is that you usually won't see the same accuracy in the end (so it happens sometimes) because half-precision is... well... not as precise ;).</p>
<h3 id="Problems-with-half-precision:">
<a class="anchor" href="#Problems-with-half-precision:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problems with half-precision:<a class="anchor-link" href="#Problems-with-half-precision:"> </a>
</h3>
<p>To understand the problems with half precision, let's look briefly at what an FP16 looks like (more information <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">here</a>).</p>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/half.png" alt="half float"></p>
<p>The sign bit gives us +1 or -1, then we have 5 bits to code an exponent between -14 and 15, while the fraction part has the remaining 10 bits. Compared to FP32, we have a smaller range of possible values (2e-14 to 2e15 roughly, compared to 2e-126 to 2e127 for FP32) but also a smaller <em>offset</em>.</p>
<p>For instance, between 1 and 2, the FP16 format only represents the number 1, 1+2e-10, 1+2*2e-10... which means that 1 + 0.0001 = 1 in half precision. That's what will cause a certain numbers of problems, specifically three that can occur and mess up your training.</p>
<ol>
<li>The weight update is imprecise: inside your optimizer, you basically do w = w - lr <em> w.grad for each weight of your network. The problem in performing this operation in half precision is that very often, w.grad is several orders of magnitude below w, and the learning rate is also small. The situation where w=1 and lr</em>w.grad is 0.0001 (or lower) is therefore very common, but the update doesn't do anything in those cases.</li>
<li>Your gradients can underflow. In FP16, your gradients can easily be replaced by 0 because they are too low.</li>
<li>Your activations or loss can overflow. The opposite problem from the gradients: it's easier to hit nan (or infinity) in FP16 precision, and your training might more easily diverge.</li>
</ol>
<h3 id="The-solution:-mixed-precision-training">
<a class="anchor" href="#The-solution:-mixed-precision-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>The solution: mixed precision training<a class="anchor-link" href="#The-solution:-mixed-precision-training"> </a>
</h3>
<p>To address those three problems, we don't fully train in FP16 precision. As the name mixed training implies, some of the operations will be done in FP16, others in FP32. This is mainly to take care of the first problem listed above. For the next two there are additional tricks.</p>
<p>The main idea is that we want to do the forward pass and the gradient computation in half precision (to go fast) but the update in single precision (to be more precise). It's okay if w and grad are both half floats, but when we do the operation w = w - lr * grad, we need to compute it in FP32. That way our 1 + 0.0001 is going to be 1.0001.</p>
<p>This is why we keep a copy of the weights in FP32 (called master model). Then, our training loop will look like:</p>
<ol>
<li>compute the output with the FP16 model, then the loss</li>
<li>back-propagate the gradients in half-precision.</li>
<li>copy the gradients in FP32 precision</li>
<li>do the update on the master model (in FP32 precision)</li>
<li>copy the master model in the FP16 model.</li>
</ol>
<p>Note that we lose precision during step 5, and that the 1.0001 in one of the weights will go back to 1. But if the next update corresponds to add 0.0001 again, since the optimizer step is done on the master model, the 1.0001 will become 1.0002 and if we eventually go like this up to 1.0005, the FP16 model will be able to tell the difference.</p>
<p>That takes care of problem 1. For the second problem, we use something called gradient scaling: to avoid the gradients getting zeroed by the FP16 precision, we multiply the loss by a scale factor (scale=512 for instance). That way we can push the gradients to the right in the next figure, and have them not become zero.</p>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/half_representation.png" alt="half float representation"></p>
<p>Of course we don't want those 512-scaled gradients to be in the weight update, so after converting them into FP32, we can divide them by this scale factor (once they have no risks of becoming 0). This changes the loop to:</p>
<ol>
<li>compute the output with the FP16 model, then the loss.</li>
<li>multiply the loss by scale then back-propagate the gradients in half-precision.</li>
<li>copy the gradients in FP32 precision then divide them by scale.</li>
<li>do the update on the master model (in FP32 precision).</li>
<li>copy the master model in the FP16 model.</li>
</ol>
<p>For the last problem, the tricks offered by NVIDIA are to leave the batchnorm layers in single precision (they don't have many weights so it's not a big memory challenge) and compute the loss in single precision (which means converting the last output of the model in single precision before passing it to the loss).</p>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/Mixed_precision.jpeg" alt="Mixed precision training"></p>
<p>Implementing all of this in the new callback system is surprisingly easy, let's dig into this!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Util-functions">
<a class="anchor" href="#Util-functions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Util functions<a class="anchor-link" href="#Util-functions"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before going in the main <code>Callback</code> we will need some helper functions. We will refactor using the <a href="https://github.com/NVIDIA/apex">APEX library</a> util functions. The python-only build is enough for what we will use here if you don't manage to do the CUDA/C++ installation.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="kn">import</span> <span class="nn">apex.fp16_utils</span> <span class="k">as</span> <span class="nn">fp16</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Converting-the-model-to-FP16">
<a class="anchor" href="#Converting-the-model-to-FP16" aria-hidden="true"><span class="octicon octicon-link"></span></a>Converting the model to FP16<a class="anchor-link" href="#Converting-the-model-to-FP16"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://course.fast.ai/videos/?lesson=12&amp;t=1425">Jump_to lesson 12 video</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will need a function to convert all the layers of the model to FP16 precision except the BatchNorm-like layers (since those need to be done in FP32 precision to be stable). We do this in two steps: first we convert the model to FP16, then we loop over all the layers and put them back to FP32 if they are a BatchNorm layer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>
<span class="n">bn_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">def</span> <span class="nf">bn_to_float</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bn_types</span><span class="p">):</span> <span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>  <span class="n">bn_to_float</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">def</span> <span class="nf">model_to_half</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">bn_to_float</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's test this:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model_to_half</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">def</span> <span class="nf">check_weights</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">]):</span>
        <span class="k">assert</span> <span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">t</span>
        <span class="k">assert</span> <span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span>   <span class="o">==</span> <span class="n">t</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="n">check_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In Apex, the function that does this for us is <code>convert_network</code>. We can use it to put the model in FP16 or back to FP32.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">fp16</span><span class="o">.</span><span class="n">convert_network</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">check_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-the-master-copy-of-the-parameters">
<a class="anchor" href="#Creating-the-master-copy-of-the-parameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating the master copy of the parameters<a class="anchor-link" href="#Creating-the-master-copy-of-the-parameters"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>From our model parameters (mostly in FP16), we'll want to create a copy in FP32 (master parameters) that we will use for the step in the optimizer. Optionally, we concatenate all the parameters to do one flat big tensor, which can make that step a little bit faster.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">parameters_to_vector</span>

<span class="k">def</span> <span class="nf">get_master</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">model_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">flat_master</span><span class="p">:</span>
        <span class="n">master_param</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">([</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_params</span><span class="p">])</span>
        <span class="n">master_param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">master_param</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">master_param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">master_param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">master_param</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">*</span><span class="n">master_param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">model_params</span><span class="p">,</span> <span class="p">[</span><span class="n">master_param</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">master_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_params</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">master_params</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The util function from Apex to do this is <code>prep_param_lists</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="n">model_p</span><span class="p">,</span><span class="n">master_p</span> <span class="o">=</span> <span class="n">get_master</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">model_p1</span><span class="p">,</span><span class="n">master_p1</span> <span class="o">=</span> <span class="n">fp16</span><span class="o">.</span><span class="n">prep_param_lists</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">def</span> <span class="nf">same_lists</span><span class="p">(</span><span class="n">ps1</span><span class="p">,</span> <span class="n">ps2</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ps1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">ps2</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">p1</span><span class="p">,</span><span class="n">p2</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ps1</span><span class="p">,</span><span class="n">ps2</span><span class="p">):</span> 
        <span class="k">assert</span> <span class="n">p1</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="n">p2</span><span class="o">.</span><span class="n">requires_grad</span>

        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">p1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">p2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="n">same_lists</span><span class="p">(</span><span class="n">model_p</span><span class="p">,</span><span class="n">model_p1</span><span class="p">)</span>
<span class="n">same_lists</span><span class="p">(</span><span class="n">model_p</span><span class="p">,</span><span class="n">master_p</span><span class="p">)</span>
<span class="n">same_lists</span><span class="p">(</span><span class="n">master_p</span><span class="p">,</span><span class="n">master_p1</span><span class="p">)</span>
<span class="n">same_lists</span><span class="p">(</span><span class="n">model_p1</span><span class="p">,</span><span class="n">master_p1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can't use flat_master when there is a mix of FP32 and FP16 parameters (like batchnorm here).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="n">model1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">fp16</span><span class="o">.</span><span class="n">convert_network</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="n">model_p</span><span class="p">,</span><span class="n">master_p</span> <span class="o">=</span> <span class="n">get_master</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model_p1</span><span class="p">,</span><span class="n">master_p1</span> <span class="o">=</span> <span class="n">fp16</span><span class="o">.</span><span class="n">prep_param_lists</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>
<span class="n">same_lists</span><span class="p">(</span><span class="n">model_p</span><span class="p">,</span><span class="n">model_p1</span><span class="p">)</span>
<span class="n">same_lists</span><span class="p">(</span><span class="n">master_p</span><span class="p">,</span><span class="n">master_p1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">master_p</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">10</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="mi">30</span> <span class="o">+</span> <span class="mi">30</span><span class="o">*</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">master_p1</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">10</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="mi">30</span> <span class="o">+</span> <span class="mi">30</span><span class="o">*</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The thing is that we don't always want all the parameters of our model in the same parameter group, because we might:</p>
<ul>
<li>want to do transfer learning and freeze some layers</li>
<li>apply discriminative learning rates</li>
<li>don't apply weight decay to some layers (like BatchNorm) or the bias terms</li>
</ul>
<p>So we actually need a function that splits the parameters of an optimizer (and not a model) according to the right parameter groups.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="k">def</span> <span class="nf">get_master</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">model_params</span> <span class="o">=</span> <span class="p">[[</span><span class="n">param</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span> <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span> <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">flat_master</span><span class="p">:</span>
        <span class="n">master_params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">model_params</span><span class="p">:</span>
            <span class="n">mp</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">([</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span><span class="p">])</span>
            <span class="n">mp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">mp</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mp</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">mp</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">*</span><span class="n">mp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
            <span class="n">master_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mp</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">master_params</span> <span class="o">=</span> <span class="p">[[</span><span class="n">param</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span><span class="p">]</span> <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">model_params</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">master_params</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Copy-the-gradients-from-model-params-to-master-params">
<a class="anchor" href="#Copy-the-gradients-from-model-params-to-master-params" aria-hidden="true"><span class="octicon octicon-link"></span></a>Copy the gradients from model params to master params<a class="anchor-link" href="#Copy-the-gradients-from-model-params-to-master-params"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After the backward pass, all gradients must be copied to the master params before the optimizer step can be done in FP32. We need a function for that (with a bit of adjustement if we have flat master).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="k">def</span> <span class="nf">to_master_grads</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span><span class="p">,</span> <span class="n">flat_master</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">-&gt;</span><span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">flat_master</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">master_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">master_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">master_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">*</span><span class="n">master_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="n">master_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">parameters_to_vector</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model_params</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">master</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">master</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">master</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">master</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">*</span><span class="n">master</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
                <span class="n">master</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="n">master</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The corresponding function in the Apex utils is <code>model_grads_to_master_grads</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">20</span><span class="p">,))</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="n">to_master_grads</span><span class="p">(</span><span class="n">model_p</span><span class="p">,</span> <span class="n">master_p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="k">def</span> <span class="nf">check_grads</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">p1</span><span class="p">,</span><span class="n">p2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span><span class="n">m2</span><span class="p">):</span> 
        <span class="k">if</span> <span class="n">p1</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="k">assert</span> <span class="n">p2</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span>

        <span class="k">else</span><span class="p">:</span> <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">p1</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">p2</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="n">check_grads</span><span class="p">(</span><span class="n">model_p</span><span class="p">,</span> <span class="n">master_p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="n">fp16</span><span class="o">.</span><span class="n">model_grads_to_master_grads</span><span class="p">(</span><span class="n">model_p</span><span class="p">,</span> <span class="n">master_p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="n">check_grads</span><span class="p">(</span><span class="n">model_p</span><span class="p">,</span> <span class="n">master_p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Copy-the-master-params-to-the-model-params">
<a class="anchor" href="#Copy-the-master-params-to-the-model-params" aria-hidden="true"><span class="octicon octicon-link"></span></a>Copy the master params to the model params<a class="anchor-link" href="#Copy-the-master-params-to-the-model-params"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After the step, we need to copy back the master parameters to the model parameters for the next update.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="kn">from</span> <span class="nn">torch._utils</span> <span class="kn">import</span> <span class="n">_unflatten_dense_tensors</span>

<span class="k">def</span> <span class="nf">to_model_params</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span><span class="p">,</span> <span class="n">flat_master</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">-&gt;</span><span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">flat_master</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">master</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">_unflatten_dense_tensors</span><span class="p">(</span><span class="n">master_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">model_params</span><span class="p">)):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">master</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">master</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span><span class="p">):</span> <span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">master</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The corresponding function in Apex is <code>master_params_to_model_params</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="But-we-need-to-handle-param-groups">
<a class="anchor" href="#But-we-need-to-handle-param-groups" aria-hidden="true"><span class="octicon octicon-link"></span></a>But we need to handle param groups<a class="anchor-link" href="#But-we-need-to-handle-param-groups"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The thing is that we don't always want all the parameters of our model in the same parameter group, because we might:</p>
<ul>
<li>want to do transfer learning and freeze some layers</li>
<li>apply discriminative learning rates</li>
<li>don't apply weight decay to some layers (like BatchNorm) or the bias terms</li>
</ul>
<p>So we actually need a function that splits the parameters of an optimizer (and not a model) according to the right parameter groups and the following functions need to handle lists of lists of parameters (one list of each param group in <code>model_pgs</code> and <code>master_pgs</code>)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>
<span class="k">def</span> <span class="nf">get_master</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">model_pgs</span> <span class="o">=</span> <span class="p">[[</span><span class="n">param</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span> <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span> <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">flat_master</span><span class="p">:</span>
        <span class="n">master_pgs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">model_pgs</span><span class="p">:</span>
            <span class="n">mp</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">([</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span><span class="p">])</span>
            <span class="n">mp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">mp</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mp</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">mp</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">*</span><span class="n">mp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
            <span class="n">master_pgs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">mp</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">master_pgs</span> <span class="o">=</span> <span class="p">[[</span><span class="n">param</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span><span class="p">]</span> <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">model_pgs</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">master_pgs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pg</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_pgs</span><span class="p">,</span> <span class="n">master_pgs</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="k">def</span> <span class="nf">to_master_grads</span><span class="p">(</span><span class="n">model_pgs</span><span class="p">,</span> <span class="n">master_pgs</span><span class="p">,</span> <span class="n">flat_master</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">-&gt;</span><span class="kc">None</span><span class="p">:</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">model_params</span><span class="p">,</span><span class="n">master_params</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_pgs</span><span class="p">,</span><span class="n">master_pgs</span><span class="p">):</span>
        <span class="n">fp16</span><span class="o">.</span><span class="n">model_grads_to_master_grads</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="n">flat_master</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="k">def</span> <span class="nf">to_model_params</span><span class="p">(</span><span class="n">model_pgs</span><span class="p">,</span> <span class="n">master_pgs</span><span class="p">,</span> <span class="n">flat_master</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">-&gt;</span><span class="kc">None</span><span class="p">:</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">model_params</span><span class="p">,</span><span class="n">master_params</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_pgs</span><span class="p">,</span><span class="n">master_pgs</span><span class="p">):</span>
        <span class="n">fp16</span><span class="o">.</span><span class="n">master_params_to_model_params</span><span class="p">(</span><span class="n">model_params</span><span class="p">,</span> <span class="n">master_params</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="n">flat_master</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-main-Callback">
<a class="anchor" href="#The-main-Callback" aria-hidden="true"><span class="octicon octicon-link"></span></a>The main Callback<a class="anchor-link" href="#The-main-Callback"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://course.fast.ai/videos/?lesson=12&amp;t=1452">Jump_to lesson 12 video</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="k">class</span> <span class="nc">MixedPrecision</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="n">_order</span> <span class="o">=</span> <span class="mi">99</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span><span class="p">,</span> <span class="s2">"Mixed precision training requires cudnn."</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span> <span class="o">=</span> <span class="n">loss_scale</span><span class="p">,</span><span class="n">flat_master</span>

    <span class="k">def</span> <span class="nf">begin_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">fp16</span><span class="o">.</span><span class="n">convert_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span> <span class="o">=</span> <span class="n">get_master</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span><span class="p">)</span>
        <span class="c1">#Changes the optimizer so that the optimization step is done in FP32.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span> <span class="c1">#Put those param groups inside our runner.</span>
        
    <span class="k">def</span> <span class="nf">after_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">begin_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">xb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">xb</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="c1">#Put the inputs to half precision</span>
    <span class="k">def</span> <span class="nf">after_pred</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1">#Compute the loss in FP32</span>
    <span class="k">def</span> <span class="nf">after_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">loss</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="c1">#Loss scaling to avoid gradient underflow</span>

    <span class="k">def</span> <span class="nf">after_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#Copy the gradients to master and unscale</span>
        <span class="n">to_master_grads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">master_params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">master_params</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">after_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#Zero the gradients of the model since the optimizer is disconnected.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1">#Update the params from master to model.</span>
        <span class="n">to_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's test this on Imagenette</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"/media/cedric/Datasets/imagenette2-160/"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="n">tfms</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_rgb</span><span class="p">,</span> <span class="n">ResizeFixed</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">to_byte_tensor</span><span class="p">,</span> <span class="n">to_float_tensor</span><span class="p">]</span>
<span class="n">bs</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">il</span> <span class="o">=</span> <span class="n">ImageList</span><span class="o">.</span><span class="n">from_files</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">)</span>
<span class="n">sd</span> <span class="o">=</span> <span class="n">SplitData</span><span class="o">.</span><span class="n">split_by_func</span><span class="p">(</span><span class="n">il</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">grandparent_splitter</span><span class="p">,</span> <span class="n">valid_name</span><span class="o">=</span><span class="s1">'val'</span><span class="p">))</span>
<span class="n">ll</span> <span class="o">=</span> <span class="n">label_by_func</span><span class="p">(</span><span class="n">sd</span><span class="p">,</span> <span class="n">parent_labeler</span><span class="p">,</span> <span class="n">proc_y</span><span class="o">=</span><span class="n">CategoryProcessor</span><span class="p">())</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ll</span><span class="o">.</span><span class="n">to_databunch</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_in</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">c_out</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="n">nfs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">512</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show </span>

<span class="k">def</span> <span class="nf">get_learner</span><span class="p">(</span><span class="n">nfs</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">,</span>
                <span class="n">cb_funcs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">adam_opt</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">get_cnn_model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nfs</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">init_cnn</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Learner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">cb_funcs</span><span class="o">=</span><span class="n">cb_funcs</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">opt_func</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Training without mixed precision</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">cbfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">AvgStatsCallback</span><span class="p">,</span><span class="n">accuracy</span><span class="p">),</span>
        <span class="n">ProgressCallback</span><span class="p">,</span>
        <span class="n">CudaCallback</span><span class="p">,</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">BatchTransformXCallback</span><span class="p">,</span> <span class="n">norm_imagenette</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">get_learner</span><span class="p">(</span><span class="n">nfs</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">,</span> <span class="n">cb_funcs</span><span class="o">=</span><span class="n">cbfs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      &lt;progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
      
    </div>
    

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_accuracy</th>
      <th>valid_loss</th>
      <th>valid_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.912490</td>
      <td>0.384624</td>
      <td>1.778356</td>
      <td>0.445096</td>
      <td>00:06</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Training with mixed precision</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">cbfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">AvgStatsCallback</span><span class="p">,</span><span class="n">accuracy</span><span class="p">),</span>
        <span class="n">CudaCallback</span><span class="p">,</span>
        <span class="n">ProgressCallback</span><span class="p">,</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">BatchTransformXCallback</span><span class="p">,</span> <span class="n">norm_imagenette</span><span class="p">),</span>
        <span class="n">MixedPrecision</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">get_learner</span><span class="p">(</span><span class="n">nfs</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">,</span> <span class="n">cb_funcs</span><span class="o">=</span><span class="n">cbfs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      &lt;progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
      
    </div>
    

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_accuracy</th>
      <th>valid_loss</th>
      <th>valid_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.057630</td>
      <td>0.339423</td>
      <td>1.800098</td>
      <td>0.424204</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">test_eq</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">type</span><span class="p">(),</span> <span class="s1">'torch.cuda.FloatTensor'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dynamic-loss-scaling">
<a class="anchor" href="#Dynamic-loss-scaling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dynamic loss scaling<a class="anchor-link" href="#Dynamic-loss-scaling"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The only annoying thing with the previous implementation of mixed precision training is that it introduces one new hyper-parameter to tune, the value of the loss scaling. Fortunately for us, there is a way around this. We want the loss scaling to be as high as possible so that our gradients can use the whole range of representation, so let's first try a really high value. In all likelihood, this will cause our gradients or our loss to overflow, and we will try again with half that big value, and again, until we get to the largest loss scale possible that doesn't make our gradients overflow.</p>
<p>This value will be perfectly fitted to our model and can continue to be dynamically adjusted as the training goes, if it's still too high, by just halving it each time we overflow. After a while though, training will converge and gradients will start to get smaller, so we also need a mechanism to get this dynamic loss scale larger if it's safe to do so. The strategy used in the Apex library is to multiply the loss scale by 2 each time we had a given number of iterations without overflowing.</p>
<p>To check if the gradients have overflowed, we check their sum (computed in FP32). If one term is nan, the sum will be nan. Interestingly, on the GPU, it's faster than checking <code>torch.isnan</code>:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://course.fast.ai/videos/?lesson=12&amp;t=1472">Jump_to lesson 12 video</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">def</span> <span class="nf">test_overflow</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">s</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span> <span class="ow">or</span> <span class="n">s</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">)</span> <span class="ow">or</span> <span class="n">s</span> <span class="o">!=</span> <span class="n">s</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">1024</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">test_overflow</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>False</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">x</span><span class="p">[</span><span class="mi">123</span><span class="p">,</span><span class="mi">145</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>
<span class="n">test_overflow</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="o">%</span><span class="k">timeit</span> test_overflow(x)
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>35.1 Âµs Â± 3.87 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="o">%</span><span class="k">timeit</span> torch.isnan(x).any().item()
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>41.1 Âµs Â± 643 ns per loop (mean Â± std. dev. of 7 runs, 10000 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we can use it in the following function that checks for gradient overflow:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">def</span> <span class="nf">grad_overflow</span><span class="p">(</span><span class="n">param_groups</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">param_groups</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">s</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span> <span class="ow">or</span> <span class="n">s</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">)</span> <span class="ow">or</span> <span class="n">s</span> <span class="o">!=</span> <span class="n">s</span><span class="p">:</span> <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And now we can write a new version of the <code>Callback</code> that handles dynamic loss scaling.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description" open="">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse_show</span>

<span class="k">class</span> <span class="nc">MixedPrecision</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="n">_order</span> <span class="o">=</span> <span class="mi">99</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">flat_master</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_loss_scale</span><span class="o">=</span><span class="mf">2.</span><span class="o">**</span><span class="mi">24</span><span class="p">,</span> <span class="n">div_factor</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span>
                 <span class="n">scale_wait</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span><span class="p">,</span> <span class="s2">"Mixed precision training requires cudnn."</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">max_loss_scale</span> <span class="o">=</span> <span class="n">flat_master</span><span class="p">,</span><span class="n">dynamic</span><span class="p">,</span><span class="n">max_loss_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">div_factor</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_wait</span> <span class="o">=</span> <span class="n">div_factor</span><span class="p">,</span><span class="n">scale_wait</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">max_loss_scale</span> <span class="k">if</span> <span class="n">dynamic</span> <span class="k">else</span> <span class="n">loss_scale</span>

    <span class="k">def</span> <span class="nf">begin_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">fp16</span><span class="o">.</span><span class="n">convert_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span> <span class="o">=</span> <span class="n">get_master</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span><span class="p">)</span>
        <span class="c1">#Changes the optimizer so that the optimization step is done in FP32.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span> <span class="c1">#Put those param groups inside our runner.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">begin_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">xb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">xb</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="c1">#Put the inputs to half precision</span>
    <span class="k">def</span> <span class="nf">after_pred</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1">#Compute the loss in FP32</span>
    <span class="k">def</span> <span class="nf">after_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_train</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">loss</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="c1">#Loss scaling to avoid gradient underflow</span>

    <span class="k">def</span> <span class="nf">after_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#First, check for an overflow</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span> <span class="ow">and</span> <span class="n">grad_overflow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_pgs</span><span class="p">):</span>
            <span class="c1">#Divide the loss scale by div_factor, zero the grad (after_step will be skipped)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">div_factor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="k">return</span> <span class="kc">True</span> <span class="c1">#skip step and zero_grad</span>
        <span class="c1">#Copy the gradients to master and unscale</span>
        <span class="n">to_master_grads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">master_params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">master_params</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>
        <span class="c1">#Check if it's been long enough without overflow</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_wait</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">div_factor</span>

    <span class="k">def</span> <span class="nf">after_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#Zero the gradients of the model since the optimizer is disconnected.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1">#Update the params from master to model.</span>
        <span class="n">to_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">master_pgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_master</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">cbfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">AvgStatsCallback</span><span class="p">,</span><span class="n">accuracy</span><span class="p">),</span>
        <span class="n">CudaCallback</span><span class="p">,</span>
        <span class="n">ProgressCallback</span><span class="p">,</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">BatchTransformXCallback</span><span class="p">,</span> <span class="n">norm_imagenette</span><span class="p">),</span>
        <span class="n">MixedPrecision</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">get_learner</span><span class="p">(</span><span class="n">nfs</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">,</span> <span class="n">cb_funcs</span><span class="o">=</span><span class="n">cbfs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      &lt;progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
      
    </div>
    

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_accuracy</th>
      <th>valid_loss</th>
      <th>valid_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.027682</td>
      <td>0.328757</td>
      <td>1.863258</td>
      <td>0.434650</td>
      <td>00:06</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The loss scale used is way higher than our previous number:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">loss_scale</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>65536.0</pre>
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Cedric-Perauer/DL_from_Foundations"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/DL_from_Foundations/jupyter/2020/04/21/2fp16.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/DL_from_Foundations/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/DL_from_Foundations/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/Cedric-Perauer" title="Cedric-Perauer"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
