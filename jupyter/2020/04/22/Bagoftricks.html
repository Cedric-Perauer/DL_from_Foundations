<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Summary Bag of Tricks for Image Classification with Convolutional Neural Networks | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Summary Bag of Tricks for Image Classification with Convolutional Neural Networks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Suggesting model refinements and architecture improvements to improve upon existing architectures and accelerate training time." />
<meta property="og:description" content="Suggesting model refinements and architecture improvements to improve upon existing architectures and accelerate training time." />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_var.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-22T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Summary Bag of Tricks for Image Classification with Convolutional Neural Networks","dateModified":"2020-04-22T00:00:00-05:00","description":"Suggesting model refinements and architecture improvements to improve upon existing architectures and accelerate training time.","datePublished":"2020-04-22T00:00:00-05:00","@type":"BlogPosting","image":"https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_var.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html"},"url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/DL_from_Foundations/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/DL_from_Foundations/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Summary Bag of Tricks for Image Classification with Convolutional Neural Networks | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Summary Bag of Tricks for Image Classification with Convolutional Neural Networks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Suggesting model refinements and architecture improvements to improve upon existing architectures and accelerate training time." />
<meta property="og:description" content="Suggesting model refinements and architecture improvements to improve upon existing architectures and accelerate training time." />
<link rel="canonical" href="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html" />
<meta property="og:url" content="https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:image" content="https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_var.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-22T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Summary Bag of Tricks for Image Classification with Convolutional Neural Networks","dateModified":"2020-04-22T00:00:00-05:00","description":"Suggesting model refinements and architecture improvements to improve upon existing architectures and accelerate training time.","datePublished":"2020-04-22T00:00:00-05:00","@type":"BlogPosting","image":"https://cedric-perauer.github.io/DL_from_Foundations/images/resnet_var.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html"},"url":"https://cedric-perauer.github.io/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://cedric-perauer.github.io/DL_from_Foundations/feed.xml" title="fastpages" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/DL_from_Foundations/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/DL_from_Foundations/search/">Search</a><a class="page-link" href="/DL_from_Foundations/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Summary Bag of Tricks for Image Classification with Convolutional Neural Networks</h1><p class="page-description">Suggesting model refinements and architecture improvements to improve upon existing architectures and accelerate training time.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-22T00:00:00-05:00" itemprop="datePublished">
        Apr 22, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/DL_from_Foundations/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#What-did-the-authors-want-to-achieve-?">What did the authors want to achieve ? </a></li>
<li class="toc-entry toc-h2"><a href="#Key-elements">Key elements </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Training">Training </a></li>
<li class="toc-entry toc-h4"><a href="#Large-Batch-Size,-linear-scaling-learning-rate">Large Batch Size, linear scaling learning rate </a></li>
<li class="toc-entry toc-h4"><a href="#Low-Precision-Training">Low Precision Training </a></li>
<li class="toc-entry toc-h3"><a href="#Architecture-Improvements">Architecture Improvements </a>
<ul>
<li class="toc-entry toc-h4"><a href="#ResNet-B">ResNet-B </a></li>
<li class="toc-entry toc-h4"><a href="#ResNet-C">ResNet-C </a></li>
<li class="toc-entry toc-h4"><a href="#ResNet-D">ResNet-D </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Training-Refinements">Training Refinements </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Cosine-Learning-Rate-Decay">Cosine Learning Rate Decay </a></li>
<li class="toc-entry toc-h4"><a href="#Label-Smoothing">Label Smoothing </a></li>
<li class="toc-entry toc-h4"><a href="#Knowledge-Distillation">Knowledge Distillation </a></li>
<li class="toc-entry toc-h4"><a href="#Mixup-Training">Mixup Training </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Results-and-Conclusions">Results and Conclusions </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Object-Detection">Object Detection </a></li>
<li class="toc-entry toc-h4"><a href="#Semantic-Segmentation">Semantic Segmentation </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-22-Bagoftricks.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-did-the-authors-want-to-achieve-?">
<a class="anchor" href="#What-did-the-authors-want-to-achieve-?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What did the authors want to achieve ?<a class="anchor-link" href="#What-did-the-authors-want-to-achieve-?"> </a>
</h2>
<ul>
<li>explore refinements (Learning Rate, FP Precision,...) to improve Conv Nets</li>
<li>slight architecture improvements on ResNet to increase accuracy (stride, filter size, pooling)</li>
<li>prove the results on well known datasets (ImageNet) </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Key-elements">
<a class="anchor" href="#Key-elements" aria-hidden="true"><span class="octicon octicon-link"></span></a>Key elements<a class="anchor-link" href="#Key-elements"> </a>
</h2>
<p>Training Loop pseudocode : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/train.png" alt="images"></p>
<h4 id="Training">
<a class="anchor" href="#Training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training<a class="anchor-link" href="#Training"> </a>
</h4>
<ul>
<li>
<p>The training/model builds on a "vanilla" training loop above, the ResNet architecture which is then improved, starting with these steps :</p>
<p>1) decode random image to FP32 in a range from [0,255]<br>
2) crop random area with between [8%,100%] of total pixels and a of ration $4/3$ or $3/4$, then rescale to 224x224<br>
3) flip horizontally with probability of 0.5<br>
4) scale hue, saturation and brightness by randomly drawing from [0.6,1.4]<br>
5) Add PCA Noise w/coefficient randomly sampled from ~ $N(0,0.1)$<br>
6) normalize RGB : substract 123.68/116.779/103.939 and divide by 58.393/57.12/57.375</p>
</li>
</ul>
<p>The CNN is initalized using Xavier Init and uniformally initalizing the weights from [-a,a]
with $a =\sqrt{6 / (d_{in} + d_{out})}$ with the two $d$ values corresponding ti input and output filter size. Biases are initalized to 0 as well the Batch Norm vector $\beta 
$, $\gamma$ vectors are initalized to 1. Nesterov acclerated Momentum is used with 120 epochs and a total batch size of 256, the learning rate is initalized to 0.1 and cut by 10 at the 30th, 60th and 90th epoch.</p>
<h4 id="Large-Batch-Size,-linear-scaling-learning-rate">
<a class="anchor" href="#Large-Batch-Size,-linear-scaling-learning-rate" aria-hidden="true"><span class="octicon octicon-link"></span></a>Large Batch Size, linear scaling learning rate<a class="anchor-link" href="#Large-Batch-Size,-linear-scaling-learning-rate"> </a>
</h4>
<p>In the past using large Batch sizes has been difficult (degradation), as larger batch sizes posses less noise, the variance is smaller than on small batch sizes. 4 tricks improve upon this problem :</p>
<p>Linear Scaling Learning Rate :</p>
<ul>
<li>Linear scaling learning rate was proposed by Goyal et. al, the paper proposes that linear scaling the learning rate with batch size empirically improves ResNet training. He et. al built on this and chooses 0.1 as initial learning rate for batch size of 256. Assuming our batch size is $b$ we scale like this :<br>
$0.1 * b/256$</li>
</ul>
<p>Learning Rate Warmup :</p>
<ul>
<li>at the beginning all parameters are typically random values, therfore large learning rates can lead to numerical instability.Goyal et. al proposes a gradual learning rate increase to combat this. For that $m$ warmup epochs are selected, if our inital learning rate is $\eta$, our value depending on epoch $i$ is :<br>
$i*\eta/(m)$</li>
</ul>
<p>Zero $\gamma$:</p>
<ul>
<li>Residual Blocks can consist of Batch Norm layers at the output. Initalizing the $\gamma$ parameters of the Batch Norm layers to 0, mimics smaller networks which makes the parameters easier to initalize. That is achieved because when using 0 for intialization only the input (shortcut connection that is passed to the end of the block) is learned when both $\gamma$ and $\beta$ are zero at the inital stage. </li>
</ul>
<p>No bias decay :</p>
<ul>
<li>Weight decay is only applied to the weights and not the biases as well as the two Batch Norm hyperparamters, this avoids overfitting.    </li>
</ul>
<h4 id="Low-Precision-Training">
<a class="anchor" href="#Low-Precision-Training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Low Precision Training<a class="anchor-link" href="#Low-Precision-Training"> </a>
</h4>
<p>In order to improve training time (from 13.3 minutes w/ batch size of 256 per epoch to 4.4 minutes per epoch with batch size of 1024 for ResNet-50), FP16 is used to store activations and gradients, however copies are made in FP32 for parameter updates. Optionally multiplying a scalar to the loss can make up for the lower range of FP16.<br>
<img src="/DL_from_Foundations/images/copied_from_nb/images/resnet_var.png" alt=""></p>
<p>Over the year several improvements to the classic ResNet where introduced (picture above). The paper also introduces a new improvement.</p>
<h3 id="Architecture-Improvements">
<a class="anchor" href="#Architecture-Improvements" aria-hidden="true"><span class="octicon octicon-link"></span></a>Architecture Improvements<a class="anchor-link" href="#Architecture-Improvements"> </a>
</h3>
<h4 id="ResNet-B">
<a class="anchor" href="#ResNet-B" aria-hidden="true"><span class="octicon octicon-link"></span></a>ResNet-B<a class="anchor-link" href="#ResNet-B"> </a>
</h4>
<p>Resnet-B researchers found out that "ResNet-A" (the original version) ignores three quarters of the input map, due to a 1x1 conv with a stride of 2 in the beginning. Due to that the researchers switched the stride of 2 between the first two layers in Path A.</p>
<h4 id="ResNet-C">
<a class="anchor" href="#ResNet-C" aria-hidden="true"><span class="octicon octicon-link"></span></a>ResNet-C<a class="anchor-link" href="#ResNet-C"> </a>
</h4>
<p>This version only changes the start of the network. The computation of a 7x7 Kernel Convolution is 5.4 times slower as a 3x3 vonvolution, that's why the 7x7 Kernel with stride 2 was replaced with 3x3 Kernels (the first two are with 32 filters and stride of 2/1, while the last one has 64 filters and stride of 1).</p>
<h4 id="ResNet-D">
<a class="anchor" href="#ResNet-D" aria-hidden="true"><span class="octicon octicon-link"></span></a>ResNet-D<a class="anchor-link" href="#ResNet-D"> </a>
</h4>
<p>The approach proposed in the paper focuses on the same approach as the ResNet-B researchers did, but in this case Path B is changed. Path B also ignores 3/4 of input due to a 1x1 convolution used at the start of Path B. The paper implements an average Pooling Layer of size 2x2 with stride of 2, before the convolution (now with stride 1). The compute cost is very small. Experiments show that, ResNet-D only needs 15% more compute with a 3% lower throughput than the vanilla architecture.</p>
<h3 id="Training-Refinements">
<a class="anchor" href="#Training-Refinements" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training Refinements<a class="anchor-link" href="#Training-Refinements"> </a>
</h3>
<h4 id="Cosine-Learning-Rate-Decay">
<a class="anchor" href="#Cosine-Learning-Rate-Decay" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cosine Learning Rate Decay<a class="anchor-link" href="#Cosine-Learning-Rate-Decay"> </a>
</h4>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/res_anneal.png" alt=""></p>
<p>Cosine annealing (1) is used to decay the learning rate (compared to divsion by 10 every 30 epochs in He et. al). $T$ is the total number of batches. Compared to the step decay, the
cosine decay starts to decay the learning since the beginning, but remains large until step decay reduces the learning rate by 10x, which potentially improves the training progress.</p>
<h4 id="Label-Smoothing">
<a class="anchor" href="#Label-Smoothing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Label Smoothing<a class="anchor-link" href="#Label-Smoothing"> </a>
</h4>
<p>During training we are minimzing Cross Entropy Loss : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/CE.png" alt=""><br>
, where $q_{i}$ is the Softmax output</p>
<p>Looking at the loss (refer to the paper), it encourages scores to be dramtically distinctive from others. Therefore label smoothing was introduced with Inception-v2 : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/smooth.png" alt=""></p>
<p>Which can generalize better, due to a finite output that is encouraged from the fully connected layer and can generalize better. In the experiments $\epsilon$ is set to 0.1 following Szegedy et al.</p>
<h4 id="Knowledge-Distillation">
<a class="anchor" href="#Knowledge-Distillation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Knowledge Distillation<a class="anchor-link" href="#Knowledge-Distillation"> </a>
</h4>
<p>With this approach a pretrained teacher model, teaches a model that has to be trained still. For example a ResNet-152 teaches a ResNet-50. A distillation loss (negative Cross Entropy loss) is used to compare the two Softmax outputs. The total loss then changes to : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/res_t.png" alt="">
, where $p$ is the true probability distribution and $z$ and $r$ are the student and learner outputs. T is set 20 here, for a pretrained ResNet-152-D model with cosine decay and label smoothing applied.</p>
<h4 id="Mixup-Training">
<a class="anchor" href="#Mixup-Training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mixup Training<a class="anchor-link" href="#Mixup-Training"> </a>
</h4>
<p>Mixup is another training refinement, according to Jeremy Howard from fastai it could be better than the other augmentation techniques and is also multidomain. Mixup samples 2 images in this case and interpolates between them (using weighted interpolation) : 
<img src="/DL_from_Foundations/images/copied_from_nb/images/mixup.png" alt=""></p>
<p>During the experiments $\alpha$ is set to 0.2 in the Beta Distribution. The # of epochs is increased from 120 to 200. Using mixup and distillation, the teacher model can be trained with mixup as well.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Results-and-Conclusions">
<a class="anchor" href="#Results-and-Conclusions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results and Conclusions<a class="anchor-link" href="#Results-and-Conclusions"> </a>
</h2>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/results_bag.png" alt=""><br>
Results can be seen in the picture above. 
FP16 further improves training by 0.5% and the ResNet-D approach improves accuracy by 1% over the standard approach.</p>
<h4 id="Object-Detection">
<a class="anchor" href="#Object-Detection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Object Detection<a class="anchor-link" href="#Object-Detection"> </a>
</h4>
<p>A VGG-19 Faster-RCNN model is trained with Detectron refinements such as linear warmup and long training schedule. Using destill with mixup the mAP can be improved from 77.54 to 81.33.</p>
<p><img src="/DL_from_Foundations/images/copied_from_nb/images/fcn_bag.png" alt=""></p>
<h4 id="Semantic-Segmentation">
<a class="anchor" href="#Semantic-Segmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Semantic Segmentation<a class="anchor-link" href="#Semantic-Segmentation"> </a>
</h4>
<p>A FCN model is used pre trained on the ADE20K dataset. Both pixel accuracy and mean intersection over union improved.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Cedric-Perauer/DL_from_Foundations"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/DL_from_Foundations/jupyter/2020/04/22/Bagoftricks.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/DL_from_Foundations/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/DL_from_Foundations/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/Cedric-Perauer" title="Cedric-Perauer"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/DL_from_Foundations/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
